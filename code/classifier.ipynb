{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import pairwise_distances\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "import embed_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph(G):\n",
    "    # G = nx.Graph()\n",
    "    # G.add_edge(1,2)\n",
    "    # G.add_edge(2,3)\n",
    "    # for v in G.nodes():\n",
    "    #     G.node[v]['state']='X'\n",
    "    # G.node[1]['state']='Y'\n",
    "    # G.node[2]['state']='Y'\n",
    "\n",
    "    # for n in G.edges_iter():\n",
    "    #     G.edge[n[0]][n[1]]['state']='X'\n",
    "    # G.edge[2][3]['state']='Y'\n",
    "\n",
    "    node_labels = nx.get_node_attributes(G,embed_utils.CLASS_NAME)\n",
    "    node_attr = nx.get_node_attributes(G,embed_utils.SENSATTR)\n",
    "\n",
    "    color_map = []\n",
    "    for node in G:\n",
    "        if node_attr[node] == 0:\n",
    "            color_map.append('blue')\n",
    "        else: \n",
    "            color_map.append('green')   \n",
    "\n",
    "    # pos = nx.spring_layout(G)\n",
    "\n",
    "    # nx.draw(G, pos)\n",
    "    nx.draw(G, node_color=color_map, labels = node_labels)\n",
    "    # nx.draw_networkx_labels(G, pos, labels = node_labels)\n",
    "    # edge_labels = nx.get_edge_attributes(G,'state')\n",
    "    # nx.draw_networkx_edge_labels(G, pos, labels = edge_labels)\n",
    "    # plt.savefig('this.png')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 138 has no neighbors.\n",
      "Node 160 has no neighbors.\n",
      "Node 245 has no neighbors.\n",
      "Node 272 has no neighbors.\n",
      "Node 355 has no neighbors.\n",
      "Node 428 has no neighbors.\n"
     ]
    }
   ],
   "source": [
    "def get_metrics(classifier, test_nodes, embeddings, label_dict):\n",
    "    test_node_embeddings = embeddings[test_nodes]\n",
    "    test_node_labels = [label_dict[node] for node in test_nodes]\n",
    "    pred = classifier.predict(test_node_embeddings)\n",
    "    accuracy = sum(test_node_labels == pred) / len(test_node_labels)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def check_classification_params(nodes, labels, embeddings):\n",
    "    assert nodes == list(range(len(nodes)))\n",
    "    assert len(labels) == len(nodes) == len(embeddings), f\"{len(labels)}, {len(nodes)}, {len(embeddings)}\"\n",
    "\n",
    "\n",
    "def make_classification_model(nodes, labels, embeddings):\n",
    "    \"\"\"\n",
    "    Makes the classification model\n",
    "    :param nodes: should be the nodes as list of consecutive integers\n",
    "    :param labels: should be a list of labels where a value of -1\n",
    "        indicates a missing label\n",
    "    :param embeddings: is the embeddings of all nodes obtained using a\n",
    "        (modified) random walk\n",
    "\n",
    "    :returns: a model with a predict() function that predicts the label\n",
    "        from embeddings\n",
    "    \"\"\"\n",
    "    check_classification_params(nodes, labels, embeddings)\n",
    "\n",
    "    g = np.mean(pairwise_distances(embeddings))\n",
    "    # TODO is this the right kernel?\n",
    "    clf = LabelPropagation(kernel=\"knn\", gamma = g).fit(embeddings, labels)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def run_classification(graph, embeddings, name_ds=\"\"):\n",
    "    # show_graph(graph)\n",
    "\n",
    "    # print(\"Graph info\")\n",
    "    # print(f\"Number of nodes: {len(graph.nodes())}\")\n",
    "    # print(f\"Number of edges: {len(graph.edges())}\")\n",
    "    # print(f\"Length label dict: {len(nx.get_node_attributes(graph, embed_utils.CLASS_NAME))}\")\n",
    "    # print(f\"Length attri dict: {len(nx.get_node_attributes(graph, embed_utils.SENSATTR))}\")\n",
    "    # print(\"Label dict:\", nx.get_node_attributes(graph, embed_utils.CLASS_NAME))\n",
    "    # print(\"Attri dict:\", nx.get_node_attributes(graph, embed_utils.SENSATTR))\n",
    "\n",
    "    # Get labels and attributes of test nodes to other classes\n",
    "    label_dict = deepcopy(nx.get_node_attributes(graph, embed_utils.CLASS_NAME))\n",
    "    attr_dict = deepcopy(nx.get_node_attributes(graph, embed_utils.SENSATTR))\n",
    "    \n",
    "    # Split in to equal sized train and test nodes\n",
    "    nodes = list(graph.nodes())\n",
    "    train_nodes, test_nodes = train_test_split(nodes, test_size=0.5, shuffle=True)\n",
    "    train_nodes = set(train_nodes)\n",
    "\n",
    "    # Get semi-supervised labels\n",
    "    n_unique_labels = len(set(label_dict.values()))\n",
    "    unique_labels = (x for x in np.arange(n_unique_labels+1, len(train_nodes) + n_unique_labels + 2))\n",
    "    semi_supervised_y = [label_dict[node] if node in train_nodes else next(unique_labels) for node in nodes]\n",
    "\n",
    "    # Train the classifier\n",
    "    clf = make_classification_model(nodes, semi_supervised_y, embeddings)\n",
    "\n",
    "    # test_node_embeddings = [emb for i, emb in enumerate(embeddings) if i in test_nodes]\n",
    "    # test_node_labels = [label_dict[node] for node in test_nodes]\n",
    "    # pred = classifier.predict(test_node_embeddings)\n",
    "    # accuracy = sum(test_node_labels == pred) / len(test_node_labels)\n",
    "\n",
    "    # Get test node embeddings, labels and find accuracy on test nodes\n",
    "    c0_nodes = [node for node in test_nodes if attr_dict[node] == 0]\n",
    "    acc_c0 = get_metrics(clf, c0_nodes, embeddings, label_dict) * 100\n",
    "\n",
    "    c1_nodes = [node for node in test_nodes if attr_dict[node] == 1]\n",
    "    acc_c1 = get_metrics(clf, c1_nodes, embeddings, label_dict) * 100\n",
    "\n",
    "    accuracy = get_metrics(clf, test_nodes, embeddings, label_dict) * 100\n",
    "    disparity = np.var([acc_c0, acc_c1])\n",
    "    # print(f\"Accuracy c0: {acc_c0}\")\n",
    "    # print(f\"Accuracy c1: {acc_c1}\")\n",
    "    # print(f\"Disparity: {disparity}\") \n",
    "    # print()\n",
    "\n",
    "    # print(f\"Total accuracy: {accuracy}\")\n",
    "    # print()\n",
    "    # print(f\"Counter training lables: {Counter([label_dict[node] for node in train_nodes]).most_common(3)}\")\n",
    "    # print(f\"Counter real lables: {Counter([label_dict[node] for node in test_nodes]).most_common(3)}\")\n",
    "    # print(\n",
    "    #     f\"Counter prediction: {Counter(clf.predict([emb for i, emb in enumerate(embeddings) if i in test_nodes])).most_common(3)}\"\n",
    "    #     )\n",
    "    # print()\n",
    "\n",
    "    return accuracy, disparity\n",
    "\n",
    "\n",
    "n_runs = 200\n",
    "experiment_settings = [\n",
    "    ['rice', 'default', 'deepwalk'],\n",
    "    ['rice', 'fairwalk', 'deepwalk'],\n",
    "    [\"rice\", \"crosswalk\", \"deepwalk\"],\n",
    "]\n",
    "acc_list = []\n",
    "disp_list = []\n",
    "for dataset, reweight_method, embed_method in experiment_settings:\n",
    "    # get graph from data\n",
    "    graph = embed_utils.data2graph(dataset)\n",
    "\n",
    "    # get embedding from graph\n",
    "    embed = embed_utils.graph2embed(\n",
    "                                        graph, \n",
    "                                        reweight_method, \n",
    "                                        embed_method\n",
    "                                        )\n",
    "\n",
    "    accs = []\n",
    "    disparities = []\n",
    "    for i in range(n_runs):\n",
    "        acc, disparity = run_classification(graph, embed)\n",
    "        accs.append(acc)\n",
    "        disparities.append(disparity)\n",
    "    acc_list.append(accs)\n",
    "    disp_list.append(disparities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(28.730941704035878, 11.244185302408548)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs), np.mean(disparities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(7.962174988437329, 268.7687250805222)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(accs), np.var(disparities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reweighting method: default\n",
      "Accuracy: 79.24439461883408\n",
      "Disparity: 205.2821218107538\n",
      "\n",
      "Reweighting method: fairwalk\n",
      "Accuracy: 74.33632286995517\n",
      "Disparity: 119.0225343476247\n",
      "\n",
      "Reweighting method: crosswalk\n",
      "Accuracy: 30.132286995515695\n",
      "Disparity: 17.542225623210268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [reweight_method for  _, reweight_method, _ in experiment_settings]\n",
    "for name, accs, disps in zip(names, acc_list, disp_list):\n",
    "    print(f'Reweighting method: {name}')\n",
    "    print(f\"Accuracy: {np.mean(accs)}\")\n",
    "    print(f'Acc')\n",
    "    print(f\"Disparity: {np.mean(disps)}\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.23766816143497\n",
      "113.94896059386294\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(acc_list))\n",
    "print(np.mean(disp_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.24439461883408, 74.33632286995517, 30.132286995515695]\n",
      "[[72.19730941704036, 84.30493273542601], [66.81614349775785, 79.82062780269058], [22.869955156950674, 36.771300448430495]]\n"
     ]
    }
   ],
   "source": [
    "acc_means = [np.mean(accs) for accs in acc_list]\n",
    "print(acc_means)\n",
    "acc_minmax = [[np.min(accs), np.max(accs)] for accs in acc_list]\n",
    "print(acc_minmax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205.2821218107538, 119.0225343476247, 17.542225623210268]\n",
      "[[47.149340227244736, 531.0282388874407], [0.1505356222488088, 415.8686224489794], [0.00014172335600909044, 84.62145181619547]]\n"
     ]
    }
   ],
   "source": [
    "disp_means = [np.mean(disps) for disps in disp_list]\n",
    "print(disp_means)\n",
    "disp_minmax = [[np.min(disps), np.max(disps)] for disps in disp_list]\n",
    "print(disp_minmax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "004704e42d79ced63795043d89add8ae96304b2a7499c0b7ffed044fe8a1d5bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
